>> PairRDD <<


// 4-8 reduceByKey, mapValues
// key 별로 value 들의 avarage 를 구하기
val data = List(("panda", 0), ("pink", 3), ("pirate", 3), ("panda", 1), ("pink", 4))
val pair = sc.parallelize(data.map(x => (x, 1)))
// var pair = sc.parallelize(data.map{ case (x, y) => (x, y, 1) }
val pair_map = pair.mapValues(x => (x, 1))
val pair_reduce = pair_map.reduceByKey((x, y) => (x._1 + y._1, x._2 + y._2))
val pair_avr = pair_reduce.mapValues(x => (x._1, x._2, "avr = " + x._1.toFloat / x._2))


// 4-10 reduceByKey
// word counting
val alice = sc.textFile("alice.txt")
val words = alice.flatMap(x => x.split(" "))
val countMap = words.countByValue()
val result = words.map(x => (x, 1)).reduceByKey((x, y) => x + y)

// why doesn't sort function work properly?
// result.collect().sortBy(_._1).foreach(println)


// 4-13 combineByKey
// key 가 value 를 가지고 있을 때, key 별 value 의 평균을 구함 (word counting 에는 적합하지 않음)
val data = List(("panda", 0), ("pink", 3), ("pirate", 3), ("panda", 1), ("pink", 4))
val pair = sc.parallelize(data)
val avrResult = pair.combineByKey(
  v => (v, 1),                                      // value 가 (value, 1) 로 매핑됨.
  (acc: (Int, Int), v) => (acc._1 + v, acc._2 + 1), // 특정 key 에 대한 (value, Int) 와 미처리 value 를 묶어서 처리.
  (acc1: (Int, Int), acc2: (Int, Int)) => (acc1._1 + acc2._1, acc1._2 + acc2._2) ).map {
    case (key, value) => (key, value._1 / value._2.toFloat) }
                                                    // partition 간 동일 (value, Int) 2개를 묶어서 처리.
val resultMap = avrResult.collectAsMap()
resultMap.map(println)    // collect() 하고 Map 화한 다음, println(_) 을 돌려줌.


// 4-17 join
// 안되네?
class Store(name: String) extends Serializable

val storeAddress = sc.parallelize(Seq(
  (new Store("Ritual"), "1026 Valencia St"), (new Store("Philz"), "748 Van Ness Ave"),
  (new Store("Philz"), "3101 24th St"), (new Store("Starbucks"), "Seattle")) )

val storeRating = sc.parallelize(Seq(
  (new Store("Ritual"), 4.9), (new Store("Philz"), 4.8) ))

val join = storeAddress.join(storeRating)
join.map(println)
